{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test_with_solutions.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make sure that count(insult) == count(non_insult) in train data\n",
    "X_train_ins = train_data.loc[train_data['Insult'] == 1]['Comment'].values\n",
    "y_train_ins = train_data.loc[train_data['Insult'] == 1]['Insult'].values\n",
    "\n",
    "X_train_non_ins = train_data.loc[train_data['Insult'] == 0]['Comment'].values\n",
    "y_train_non_ins = train_data.loc[train_data['Insult'] == 0]['Insult'].values\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(len(X_train_ins)):\n",
    "    X_train.append(X_train_ins[i])\n",
    "    X_train.append(X_train_non_ins[i])\n",
    "    \n",
    "    y_train.append(y_train_ins[i])\n",
    "    y_train.append(y_train_non_ins[i])\n",
    "\n",
    "\n",
    "X_test = test_data['Comment'].values\n",
    "y_test = test_data['Insult'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_words(line):\n",
    "    return [x for x in re.split('[_\\n ,.?!@#$%^&*():;\"\\'\\/\\\\0-9\\{2}\\\\\\<>+=_\\-]', line.lower().strip()) if x != '']\n",
    "\n",
    "def append_words_from_lines(words, lines):\n",
    "    for line in lines:\n",
    "        for word in get_words(line):\n",
    "            if word not in words and word:\n",
    "                words.append(word)\n",
    "\n",
    "vocab = []\n",
    "\n",
    "append_words_from_lines(vocab, train_data['Comment'].values)\n",
    "append_words_from_lines(vocab, test_data['Comment'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21041"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you', 'fuck', 'your', 'dad', 'i', 'really', 'don', 't', 'understand', 'point', 'xa', 'it', 'seems', 'that', 'are', 'mixing', 'apples', 'and', 'oranges', 'a', 'xc', 'majority', 'of', 'canadians', 'can', 'has', 'been', 'wrong', 'before', 'now', 'will', 'be', 'again', 'n', 'nunless', 're', 'supportive', 'the', 'idea', 'nothing', 'is', 'full', 'proof', 'or', 'perfect', 'so', 'take', 'chances', 'if', 'we', 'should', 'inadvertently', 'kill', 'son', 'daughter', 'then', 'them', 's', 'breaks', 'always', 'regard', 'as', 'collateral', 'damage', 'like', 'in', 'wartime', 'sorry', 'but', 'cheques', 'mail', 'listen', 'dont', 'wanna', 'get', 'married', 'to', 'man', 'women', 'do', 'what', 'would', 'bother', 'gay', 'people', 'got', 'stay', 'lane', 'let', 'god', 'nice', 'quick', 'judg', 'not', 'him', 'thought', 'wasnt', 'suppose', 'judge', 'c', 'xe', 'b', 'u', 'ea', 'xu', 'ed', 'ng', 'eddng', 'bi', 'ec', 'xecnh', 'xf', 'ho', 'kh', 'nc', 'd', 'cu', 'xed', 'chi', 'ee', 'nh', 'gi', 'eef', 'edf', 'v', 'giang', 'th', 'nr', 'g', 'xec', 'ch', 'xfang', 'ta', 'ebft', 'nai', 'y', 'xeau', 'chu', 'khi', 'eadt', 'ef', 'ebfn', 'sau', 'tranh', 'm', 'nkh', 'con', 'o', 'ecdn', 'eebng', 'xeam', 'sdl', 'ok', 'hope', 'they', 'sign', 'one', 'year', 'contract', 'start', 'with', 'give', 'chance', 'reliable', 'productive', 'themselves', 'out', 'all', 'his', 'time', 'off', 'hurt', 'playing', 'skills', 'he', 'falls', 'back', 'into', 'old', 'habits', 'yeah', 'where', 'shut', 'up', 'rest', 'faggot', 'friends', 'burned', 'at', 'stake', 'either', 'fake', 'extremely', 'stupid', 'maybe', 'both', 'an', 'idiot', 'who', 'understands', 'neither', 'taxation', 'nor', 'health', 'jdstorm', 'wish', 'injury', 'happened', 'on', 'its', 'own', 'doubt', 'injured', 'looked', 'embarrassed', 'me', 'careful', 'jimbo', 'og', 'fork', 'name', 'tonnyb', 'just', 'pay', 'attention', 'hmmm', 'perhaps', 'some', 'too', 'pig', 'faced', 'laid', 'therefore', 'have', 'zero', 'getting', 'pregnant', 'from', 'such', 'activity', 'hold', 'something', 'against', 'idk', 'stream', 'consciousnees', 'after', 'looking', 'her', 'barrettmarson', 'huh', 'income', 'was', 'spending', 'my', 'math', 'puts', 'for', 'reason', 'sound', 'retarded', 'lol', 'damn', 'negro', 'racist', 'screen', 'nyou', 'pieceofshit', 'oh', 'cheating', 'well', 'cup', 'cheat', 'fest', 'still', 'dare', 'post', 'comment', 'shame', 'dickhead', 'retard', 'go', 'head', 'eephusblue', 'makes', 'want', 'say', 'mike', 'macwhogal', 'http', 'www', 'youtube', 'com', 'watch', 'tlyllphkru', 'know', 've', 'holes', 'carpeting', 'land']\n"
     ]
    }
   ],
   "source": [
    "print(vocab[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import word2vecReader\n",
    "import numpy as np\n",
    "\n",
    "w2v = word2vecReader.Word2Vec.load_word2vec_format('word2vec_twitter_model/word2vec_twitter_model.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_to_vec = {}\n",
    "for word in vocab:\n",
    "    if w2v.__contains__(word):\n",
    "        word_to_vec[word] = w2v[word]\n",
    "    else:\n",
    "        word_to_vec[word] = np.zeros(400)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "seq_len = 40\n",
    "\n",
    "\n",
    "X_train_vec_seq = []\n",
    "for i, line in enumerate(X_train[::]):\n",
    "    X_train_vec_seq.append([])\n",
    "    words = get_words(line)\n",
    "    for j in range(seq_len):\n",
    "        if j < len(words):\n",
    "            X_train_vec_seq[-1].append(word_to_vec[words[j]])\n",
    "        else:\n",
    "            X_train_vec_seq[-1].append(np.zeros(400))\n",
    "X_train_vec_seq = torch.from_numpy(np.array(X_train_vec_seq)).type(torch.FloatTensor)\n",
    "            \n",
    "X_test_vec_seq = []\n",
    "for i, line in enumerate(X_test[::]):\n",
    "    X_test_vec_seq.append([])\n",
    "    words = get_words(line)\n",
    "    for j in range(seq_len):\n",
    "        if j < len(words):\n",
    "            X_test_vec_seq[-1].append(word_to_vec[words[j]])\n",
    "        else:\n",
    "            X_test_vec_seq[-1].append(np.zeros(400))\n",
    "X_test_vec_seq = torch.from_numpy(np.array(X_test_vec_seq)).type(torch.FloatTensor)\n",
    "\n",
    "y_train_torch = torch.from_numpy(np.array(y_train[::]))   \n",
    "y_test_torch = torch.from_numpy(np.array(test_data['Insult'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(X_train_vec_seq[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "sequence_length = seq_len\n",
    "input_size = 400\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "num_classes = 2\n",
    "batch_size = len(X_train_vec_seq)\n",
    "num_epochs = 500\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN (\n",
       "  (lstm): LSTM(400, 64, num_layers=2, batch_first=True)\n",
       "  (fc): Linear (64 -> 2)\n",
       "  (log_softmax): Softmax ()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN Model (Many-to-One)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True).cuda()\n",
    "        self.fc = nn.Linear(hidden_size, num_classes).cuda()\n",
    "        self.log_softmax = nn.Softmax().cuda()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states \n",
    "        h0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).cuda()\n",
    "        c0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)).cuda()\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.lstm(x, (h0, c0))  \n",
    "        \n",
    "        # Decode hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])  \n",
    "        out = self.log_softmax(out)\n",
    "        return out\n",
    "\n",
    "rnn = RNN(input_size, hidden_size, num_layers, num_classes)\n",
    "rnn.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adagrad(rnn.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#optimizer.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/500], Loss: 0.8132\n",
      "Epoch [20/500], Loss: 0.8119\n",
      "Epoch [30/500], Loss: 0.7045\n",
      "Epoch [40/500], Loss: 0.6895\n",
      "Epoch [50/500], Loss: 0.6954\n",
      "Epoch [60/500], Loss: 0.6882\n",
      "Epoch [70/500], Loss: 0.6876\n",
      "Epoch [80/500], Loss: 0.6859\n",
      "Epoch [90/500], Loss: 0.6917\n",
      "Epoch [100/500], Loss: 0.6993\n",
      "Epoch [110/500], Loss: 0.6910\n",
      "Epoch [120/500], Loss: 0.6889\n",
      "Epoch [130/500], Loss: 0.6876\n",
      "Epoch [140/500], Loss: 0.6833\n",
      "Epoch [150/500], Loss: 0.6840\n",
      "Epoch [160/500], Loss: 0.6640\n",
      "Epoch [170/500], Loss: 0.6476\n",
      "Epoch [180/500], Loss: 0.6321\n",
      "Epoch [190/500], Loss: 0.6188\n",
      "Epoch [200/500], Loss: 0.6369\n",
      "Epoch [210/500], Loss: 0.6080\n",
      "Epoch [220/500], Loss: 0.5896\n",
      "Epoch [230/500], Loss: 0.5806\n",
      "Epoch [240/500], Loss: 0.5799\n",
      "Epoch [250/500], Loss: 0.5870\n",
      "Epoch [260/500], Loss: 0.5843\n",
      "Epoch [270/500], Loss: 0.5511\n",
      "Epoch [280/500], Loss: 0.5339\n",
      "Epoch [290/500], Loss: 0.5236\n",
      "Epoch [300/500], Loss: 0.5128\n",
      "Epoch [310/500], Loss: 0.4825\n",
      "Epoch [320/500], Loss: 0.5366\n",
      "Epoch [330/500], Loss: 0.4640\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "rnn.train()\n",
    "for epoch in range(num_epochs):\n",
    "        X_train_vec_seq = X_train_vec_seq.cuda()\n",
    "        tweet = Variable(X_train_vec_seq)\n",
    "        y_train_torch = y_train_torch.cuda()\n",
    "        label = Variable(y_train_torch.view(-1))\n",
    "\n",
    "        \n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        outputs = rnn(tweet)\n",
    "\n",
    "        loss = criterion(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print ('Epoch [%d/%d], Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, loss.data[0]))\n",
    "            \n",
    "        if loss.data[0] < 0.001:\n",
    "            print('done')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def score_model(model, X, y, model_name):\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    positive = 0\n",
    "    correct_positive = 0\n",
    "    should_be_positive = 0\n",
    "\n",
    "    tweet = Variable(X)\n",
    "    label = y.view(-1)   \n",
    "    output = model(tweet)\n",
    "    a, predicted = torch.max(output.data, 1)\n",
    "\n",
    "    total += label.size(0)\n",
    "    correct += (predicted == label).sum()\n",
    "    positive += predicted.sum()\n",
    "    should_be_positive += label.sum()\n",
    "\n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i] == label[i] and label[i] == 1:\n",
    "            correct_positive += 1\n",
    "\n",
    "\n",
    "    precision = correct_positive / positive\n",
    "    recall = correct_positive / should_be_positive\n",
    "    f_score = 2 / ( (1 / precision) + (1 / recall) )\n",
    "\n",
    "\n",
    "    print('%s Accuracy: %d %%' % (model_name, 100 * correct / total)) \n",
    "    print('%s F-score: %f' % (model_name, f_score)) \n",
    "\n",
    "    \n",
    "    print('%s roc_auc_score: %f\\n' % (model_name, roc_auc_score(label.numpy(), output.data.numpy()[:, 1])))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_model(rnn, X_train_vec_seq, y_train_torch, 'Train')\n",
    "score_model(rnn, X_test_vec_seq, y_test_torch, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
