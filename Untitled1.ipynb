{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 2\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 1\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.Tensor([1]), requires_grad=True)\n",
    "w = Variable(torch.Tensor([2]), requires_grad=True)\n",
    "b = Variable(torch.Tensor([3]), requires_grad=True)\n",
    "\n",
    "# Build a computational graph.\n",
    "y = w * x + b    # y = 2 * x + 3\n",
    "\n",
    "# Compute gradients.\n",
    "y.backward()\n",
    "\n",
    "# Print out the gradients.\n",
    "print(x.grad)    # x.grad = 2 \n",
    "print(w.grad)    # w.grad = 1 \n",
    "print(b.grad)    # b.grad = 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  Parameter containing:\n",
      "-0.4766 -0.4030  0.4754\n",
      " 0.3383 -0.1227 -0.4316\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "b:  Parameter containing:\n",
      "-0.5562\n",
      "-0.4207\n",
      "[torch.FloatTensor of size 2]\n",
      "\n",
      "loss:  2.343095541000366\n",
      "dL/dw:  Variable containing:\n",
      "-1.8607 -0.3236  0.8961\n",
      " 1.4984  0.1296  0.0394\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "dL/db:  Variable containing:\n",
      "-0.9829\n",
      "-0.6786\n",
      "[torch.FloatTensor of size 2]\n",
      "\n",
      "loss:  1.3254742622375488\n",
      "loss:  0.8379558324813843\n",
      "loss:  0.5886491537094116\n",
      "loss:  0.4509824812412262\n",
      "loss:  0.3686004877090454\n",
      "loss:  0.3154529333114624\n",
      "loss:  0.2788867950439453\n",
      "loss:  0.2523779273033142\n",
      "loss:  0.23233704268932343\n",
      "loss:  0.21666112542152405\n",
      "loss:  0.20404782891273499\n",
      "loss:  0.19365337491035461\n",
      "loss:  0.1849108785390854\n",
      "loss:  0.1774286925792694\n",
      "loss:  0.170929417014122\n",
      "loss:  0.16521257162094116\n",
      "loss:  0.1601303517818451\n",
      "loss:  0.15557162463665009\n",
      "loss:  0.1514512598514557\n",
      "loss:  0.1477029025554657\n",
      "loss:  0.14427389204502106\n",
      "loss:  0.1411217898130417\n",
      "loss:  0.13821186125278473\n",
      "loss:  0.13551533222198486\n",
      "loss:  0.13300804793834686\n",
      "loss:  0.130669504404068\n",
      "loss:  0.12848228216171265\n",
      "loss:  0.12643131613731384\n",
      "loss:  0.12450353801250458\n",
      "loss:  0.12268762290477753\n",
      "loss:  0.1209736242890358\n",
      "loss:  0.1193528026342392\n",
      "loss:  0.1178174838423729\n",
      "loss:  0.11636082082986832\n",
      "loss:  0.11497674137353897\n",
      "loss:  0.11365991830825806\n",
      "loss:  0.11240547895431519\n",
      "loss:  0.11120911687612534\n",
      "loss:  0.11006695032119751\n",
      "loss:  0.10897547006607056\n",
      "loss:  0.10793150961399078\n",
      "loss:  0.10693223774433136\n",
      "loss:  0.10597503185272217\n",
      "loss:  0.1050574779510498\n",
      "loss:  0.10417740046977997\n",
      "loss:  0.10333289206027985\n",
      "loss:  0.10252201557159424\n",
      "loss:  0.10174311697483063\n",
      "loss:  0.10099460184574127\n",
      "loss:  0.10027506202459335\n",
      "loss:  0.09958311915397644\n",
      "loss:  0.09891750663518906\n",
      "loss:  0.09827704727649689\n",
      "loss:  0.09766065329313278\n",
      "loss:  0.09706731140613556\n",
      "loss:  0.09649595618247986\n",
      "loss:  0.09594576060771942\n",
      "loss:  0.09541581571102142\n",
      "loss:  0.0949053093791008\n",
      "loss:  0.09441345185041428\n",
      "loss:  0.09393952041864395\n",
      "loss:  0.09348280727863312\n",
      "loss:  0.09304262697696686\n",
      "loss:  0.09261838346719742\n",
      "loss:  0.09220941364765167\n",
      "loss:  0.09181518107652664\n",
      "loss:  0.09143514186143875\n",
      "loss:  0.09106870740652084\n",
      "loss:  0.09071540832519531\n",
      "loss:  0.09037475287914276\n",
      "loss:  0.09004627168178558\n",
      "loss:  0.08972954750061035\n",
      "loss:  0.08942408859729767\n",
      "loss:  0.08912952244281769\n",
      "loss:  0.08884546160697937\n",
      "loss:  0.08857154101133347\n",
      "loss:  0.08830732852220535\n",
      "loss:  0.08805251866579056\n",
      "loss:  0.08780677616596222\n",
      "loss:  0.08756975084543228\n",
      "loss:  0.08734113723039627\n",
      "loss:  0.0871206745505333\n",
      "loss:  0.08690799027681351\n",
      "loss:  0.0867028683423996\n",
      "loss:  0.08650502562522888\n",
      "loss:  0.08631421625614166\n",
      "loss:  0.08613012731075287\n",
      "loss:  0.08595257997512817\n",
      "loss:  0.08578135073184967\n",
      "loss:  0.08561617136001587\n",
      "loss:  0.08545684814453125\n",
      "loss:  0.0853031724691391\n",
      "loss:  0.0851549282670021\n",
      "loss:  0.08501193672418594\n",
      "loss:  0.08487401157617569\n",
      "loss:  0.08474097400903702\n",
      "loss:  0.0846126452088356\n",
      "loss:  0.08448884636163712\n",
      "loss:  0.08436944335699081\n",
      "loss:  0.08425427228212357\n",
      "loss after 1 step optimization:  0.08414318412542343\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(5, 3))\n",
    "y = Variable(torch.randn(5, 2))\n",
    "\n",
    "# Build a linear layer.\n",
    "linear = nn.Linear(3, 2)\n",
    "print ('w: ', linear.weight)\n",
    "print ('b: ', linear.bias)\n",
    "\n",
    "# Build Loss and Optimizer.\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.15)\n",
    "\n",
    "# Forward propagation.\n",
    "pred = linear(x)\n",
    "\n",
    "# Compute loss.\n",
    "loss = criterion(pred, y)\n",
    "print('loss: ', loss.data[0])\n",
    "\n",
    "# Backpropagation.\n",
    "loss.backward()\n",
    "\n",
    "# Print out the gradients.\n",
    "print ('dL/dw: ', linear.weight.grad) \n",
    "print ('dL/db: ', linear.bias.grad)\n",
    "\n",
    "# 1-step Optimization (gradient descent).\n",
    "optimizer.step()\n",
    "\n",
    "# You can also do optimization at the low level as shown below.\n",
    "# linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n",
    "# linear.bias.data.sub_(0.01 * linear.bias.grad.data)\n",
    "\n",
    "for _ in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    pred = linear(x)\n",
    "\n",
    "    # Compute loss.\n",
    "    loss = criterion(pred, y)\n",
    "    print('loss: ', loss.data[0])\n",
    "\n",
    "    # Backpropagation.\n",
    "    loss.backward()\n",
    "\n",
    "    # Print out the gradients.\n",
    "    #print ('dL/dw: ', linear.weight.grad) \n",
    "    #print ('dL/db: ', linear.bias.grad)\n",
    "\n",
    "    # 1-step Optimization (gradient descent).\n",
    "    optimizer.step()\n",
    "\n",
    "# Print out the loss after optimization.\n",
    "pred = linear(x)\n",
    "loss = criterion(pred, y)\n",
    "print('loss after 1 step optimization: ', loss.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/600], Loss: 0.1709\n",
      "Epoch [10/600], Loss: 0.1708\n",
      "Epoch [15/600], Loss: 0.1708\n",
      "Epoch [20/600], Loss: 0.1707\n",
      "Epoch [25/600], Loss: 0.1707\n",
      "Epoch [30/600], Loss: 0.1706\n",
      "Epoch [35/600], Loss: 0.1706\n",
      "Epoch [40/600], Loss: 0.1705\n",
      "Epoch [45/600], Loss: 0.1705\n",
      "Epoch [50/600], Loss: 0.1705\n",
      "Epoch [55/600], Loss: 0.1704\n",
      "Epoch [60/600], Loss: 0.1704\n",
      "Epoch [65/600], Loss: 0.1703\n",
      "Epoch [70/600], Loss: 0.1703\n",
      "Epoch [75/600], Loss: 0.1703\n",
      "Epoch [80/600], Loss: 0.1702\n",
      "Epoch [85/600], Loss: 0.1702\n",
      "Epoch [90/600], Loss: 0.1702\n",
      "Epoch [95/600], Loss: 0.1701\n",
      "Epoch [100/600], Loss: 0.1701\n",
      "Epoch [105/600], Loss: 0.1701\n",
      "Epoch [110/600], Loss: 0.1701\n",
      "Epoch [115/600], Loss: 0.1700\n",
      "Epoch [120/600], Loss: 0.1700\n",
      "Epoch [125/600], Loss: 0.1700\n",
      "Epoch [130/600], Loss: 0.1699\n",
      "Epoch [135/600], Loss: 0.1699\n",
      "Epoch [140/600], Loss: 0.1699\n",
      "Epoch [145/600], Loss: 0.1699\n",
      "Epoch [150/600], Loss: 0.1698\n",
      "Epoch [155/600], Loss: 0.1698\n",
      "Epoch [160/600], Loss: 0.1698\n",
      "Epoch [165/600], Loss: 0.1698\n",
      "Epoch [170/600], Loss: 0.1698\n",
      "Epoch [175/600], Loss: 0.1697\n",
      "Epoch [180/600], Loss: 0.1697\n",
      "Epoch [185/600], Loss: 0.1697\n",
      "Epoch [190/600], Loss: 0.1697\n",
      "Epoch [195/600], Loss: 0.1697\n",
      "Epoch [200/600], Loss: 0.1696\n",
      "Epoch [205/600], Loss: 0.1696\n",
      "Epoch [210/600], Loss: 0.1696\n",
      "Epoch [215/600], Loss: 0.1696\n",
      "Epoch [220/600], Loss: 0.1696\n",
      "Epoch [225/600], Loss: 0.1695\n",
      "Epoch [230/600], Loss: 0.1695\n",
      "Epoch [235/600], Loss: 0.1695\n",
      "Epoch [240/600], Loss: 0.1695\n",
      "Epoch [245/600], Loss: 0.1695\n",
      "Epoch [250/600], Loss: 0.1695\n",
      "Epoch [255/600], Loss: 0.1695\n",
      "Epoch [260/600], Loss: 0.1694\n",
      "Epoch [265/600], Loss: 0.1694\n",
      "Epoch [270/600], Loss: 0.1694\n",
      "Epoch [275/600], Loss: 0.1694\n",
      "Epoch [280/600], Loss: 0.1694\n",
      "Epoch [285/600], Loss: 0.1694\n",
      "Epoch [290/600], Loss: 0.1694\n",
      "Epoch [295/600], Loss: 0.1694\n",
      "Epoch [300/600], Loss: 0.1693\n",
      "Epoch [305/600], Loss: 0.1693\n",
      "Epoch [310/600], Loss: 0.1693\n",
      "Epoch [315/600], Loss: 0.1693\n",
      "Epoch [320/600], Loss: 0.1693\n",
      "Epoch [325/600], Loss: 0.1693\n",
      "Epoch [330/600], Loss: 0.1693\n",
      "Epoch [335/600], Loss: 0.1693\n",
      "Epoch [340/600], Loss: 0.1693\n",
      "Epoch [345/600], Loss: 0.1693\n",
      "Epoch [350/600], Loss: 0.1692\n",
      "Epoch [355/600], Loss: 0.1692\n",
      "Epoch [360/600], Loss: 0.1692\n",
      "Epoch [365/600], Loss: 0.1692\n",
      "Epoch [370/600], Loss: 0.1692\n",
      "Epoch [375/600], Loss: 0.1692\n",
      "Epoch [380/600], Loss: 0.1692\n",
      "Epoch [385/600], Loss: 0.1692\n",
      "Epoch [390/600], Loss: 0.1692\n",
      "Epoch [395/600], Loss: 0.1692\n",
      "Epoch [400/600], Loss: 0.1692\n",
      "Epoch [405/600], Loss: 0.1692\n",
      "Epoch [410/600], Loss: 0.1692\n",
      "Epoch [415/600], Loss: 0.1692\n",
      "Epoch [420/600], Loss: 0.1691\n",
      "Epoch [425/600], Loss: 0.1691\n",
      "Epoch [430/600], Loss: 0.1691\n",
      "Epoch [435/600], Loss: 0.1691\n",
      "Epoch [440/600], Loss: 0.1691\n",
      "Epoch [445/600], Loss: 0.1691\n",
      "Epoch [450/600], Loss: 0.1691\n",
      "Epoch [455/600], Loss: 0.1691\n",
      "Epoch [460/600], Loss: 0.1691\n",
      "Epoch [465/600], Loss: 0.1691\n",
      "Epoch [470/600], Loss: 0.1691\n",
      "Epoch [475/600], Loss: 0.1691\n",
      "Epoch [480/600], Loss: 0.1691\n",
      "Epoch [485/600], Loss: 0.1691\n",
      "Epoch [490/600], Loss: 0.1691\n",
      "Epoch [495/600], Loss: 0.1691\n",
      "Epoch [500/600], Loss: 0.1691\n",
      "Epoch [505/600], Loss: 0.1691\n",
      "Epoch [510/600], Loss: 0.1691\n",
      "Epoch [515/600], Loss: 0.1691\n",
      "Epoch [520/600], Loss: 0.1691\n",
      "Epoch [525/600], Loss: 0.1690\n",
      "Epoch [530/600], Loss: 0.1690\n",
      "Epoch [535/600], Loss: 0.1690\n",
      "Epoch [540/600], Loss: 0.1690\n",
      "Epoch [545/600], Loss: 0.1690\n",
      "Epoch [550/600], Loss: 0.1690\n",
      "Epoch [555/600], Loss: 0.1690\n",
      "Epoch [560/600], Loss: 0.1690\n",
      "Epoch [565/600], Loss: 0.1690\n",
      "Epoch [570/600], Loss: 0.1690\n",
      "Epoch [575/600], Loss: 0.1690\n",
      "Epoch [580/600], Loss: 0.1690\n",
      "Epoch [585/600], Loss: 0.1690\n",
      "Epoch [590/600], Loss: 0.1690\n",
      "Epoch [595/600], Loss: 0.1690\n",
      "Epoch [600/600], Loss: 0.1690\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f76cc757b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# Hyper Parameters\n",
    "input_size = 1\n",
    "output_size = 1\n",
    "num_epochs = 600\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Toy Dataset \n",
    "x_train = np.array([[3.3], [4.4], [5.5], [6.71], [6.93], [4.168], \n",
    "                    [9.779], [6.182], [7.59], [2.167], [7.042], \n",
    "                    [10.791], [5.313], [7.997], [3.1]], dtype=np.float32)\n",
    "\n",
    "y_train = np.array([[1.7], [2.76], [2.09], [3.19], [1.694], [1.573], \n",
    "                    [3.366], [2.596], [2.53], [1.221], [2.827], \n",
    "                    [3.465], [1.65], [2.904], [1.3]], dtype=np.float32)\n",
    "\n",
    "# Linear Regression Model\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out\n",
    "\n",
    "model = LinearRegression(input_size, output_size)\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the Model \n",
    "for epoch in range(num_epochs):\n",
    "    # Convert numpy array to torch Variable\n",
    "    inputs = Variable(torch.from_numpy(x_train))\n",
    "    targets = Variable(torch.from_numpy(y_train))\n",
    "\n",
    "    # Forward + Backward + Optimize\n",
    "    optimizer.zero_grad()  \n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 5 == 0:\n",
    "        print ('Epoch [%d/%d], Loss: %.4f' \n",
    "               %(epoch+1, num_epochs, loss.data[0]))\n",
    "        \n",
    "# Plot the graph\n",
    "predicted = model(Variable(torch.from_numpy(x_train))).data.numpy()\n",
    "plt.plot(x_train, y_train, 'ro', label='Original data')\n",
    "plt.plot(x_train, predicted, label='Fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [100/120], Loss: 1.5505\n",
      "Epoch: [2/10], Step: [100/120], Loss: 1.5656\n",
      "Epoch: [3/10], Step: [100/120], Loss: 1.5479\n",
      "Epoch: [4/10], Step: [100/120], Loss: 1.5335\n",
      "Epoch: [5/10], Step: [100/120], Loss: 1.5331\n",
      "Epoch: [6/10], Step: [100/120], Loss: 1.5161\n",
      "Epoch: [7/10], Step: [100/120], Loss: 1.5456\n",
      "Epoch: [8/10], Step: [100/120], Loss: 1.5030\n",
      "Epoch: [9/10], Step: [100/120], Loss: 1.5306\n",
      "Epoch: [10/10], Step: [100/120], Loss: 1.5213\n",
      "Accuracy of the model on the 10000 test images: 94 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Hyper Parameters \n",
    "input_size = 784\n",
    "num_classes = 10\n",
    "num_epochs = 10\n",
    "batch_size = 500\n",
    "learning_rate = 0.005\n",
    "\n",
    "# MNIST Dataset (Images and Labels)\n",
    "train_dataset = dsets.MNIST(root='./data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# Dataset Loader (Input Pipline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "# Model\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        h_num = 512\n",
    "        self.linear1 = nn.Linear(input_size, h_num)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(h_num, num_classes)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out1 = self.linear1(x)\n",
    "        rel = self.relu(out1)\n",
    "        out2 = self.linear2(rel)\n",
    "        return F.softmax(out2)\n",
    "\n",
    "model = LogisticRegression(input_size, num_classes)\n",
    "\n",
    "# Loss and Optimizer\n",
    "# Softmax is internally computed.\n",
    "# Set parameters to be updated.\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Training the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.view(-1, 28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch: [%d/%d], Step: [%d/%d], Loss: %.4f' \n",
    "                   % (epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
    "\n",
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Iter [100/600] Loss: 0.1718\n",
      "Epoch [1/5], Iter [200/600] Loss: 0.0926\n",
      "Epoch [1/5], Iter [300/600] Loss: 0.1671\n",
      "Epoch [1/5], Iter [400/600] Loss: 0.0590\n",
      "Epoch [1/5], Iter [500/600] Loss: 0.0319\n",
      "Epoch [1/5], Iter [600/600] Loss: 0.0384\n",
      "Epoch [2/5], Iter [100/600] Loss: 0.0564\n",
      "Epoch [2/5], Iter [200/600] Loss: 0.0101\n",
      "Epoch [2/5], Iter [300/600] Loss: 0.1230\n",
      "Epoch [2/5], Iter [400/600] Loss: 0.3620\n",
      "Epoch [2/5], Iter [500/600] Loss: 0.0489\n",
      "Epoch [2/5], Iter [600/600] Loss: 0.0769\n",
      "Epoch [3/5], Iter [100/600] Loss: 0.0511\n",
      "Epoch [3/5], Iter [200/600] Loss: 0.0279\n",
      "Epoch [3/5], Iter [300/600] Loss: 0.0579\n",
      "Epoch [3/5], Iter [400/600] Loss: 0.0615\n",
      "Epoch [3/5], Iter [500/600] Loss: 0.0175\n",
      "Epoch [3/5], Iter [600/600] Loss: 0.1127\n",
      "Epoch [4/5], Iter [100/600] Loss: 0.0323\n",
      "Epoch [4/5], Iter [200/600] Loss: 0.0557\n",
      "Epoch [4/5], Iter [300/600] Loss: 0.0098\n",
      "Epoch [4/5], Iter [400/600] Loss: 0.0280\n",
      "Epoch [4/5], Iter [500/600] Loss: 0.0089\n",
      "Epoch [4/5], Iter [600/600] Loss: 0.0499\n",
      "Epoch [5/5], Iter [100/600] Loss: 0.0276\n",
      "Epoch [5/5], Iter [200/600] Loss: 0.0258\n",
      "Epoch [5/5], Iter [300/600] Loss: 0.0602\n",
      "Epoch [5/5], Iter [400/600] Loss: 0.0153\n",
      "Epoch [5/5], Iter [500/600] Loss: 0.0160\n",
      "Epoch [5/5], Iter [600/600] Loss: 0.0160\n",
      "Test Accuracy of the model on the 10000 test images: 98 %\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# Hyper Parameters\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST Dataset\n",
    "train_dataset = dsets.MNIST(root='./data/',\n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data/',\n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "# CNN Model (2 conv layer)\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(7*7*32, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "        \n",
    "cnn = CNN()\n",
    "\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images)\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
    "\n",
    "# Test the Model\n",
    "cnn.eval()  # Change model to 'eval' mode (BN uses moving mean/var).\n",
    "correct = 0\n",
    "total = 0\n",
    "try:\n",
    "    for images, labels in test_loader:\n",
    "        images = Variable(images)\n",
    "        outputs = cnn(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum()\n",
    "finally:\n",
    "    pass\n",
    "\n",
    "print('Test Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "# Hyper Parameters\n",
    "sequence_length = 28\n",
    "input_size = 28\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 10\n",
    "batch_size = 8\n",
    "num_epochs = 1\n",
    "learning_rate = 0.01\n",
    "\n",
    "# MNIST Dataset\n",
    "train_dataset = dsets.MNIST(root='./data/',\n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data/',\n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "# RNN Model (Many-to-One)\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states \n",
    "        h0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) \n",
    "        c0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size))\n",
    "        \n",
    "        # Forward propagate RNN\n",
    "        out, _ = self.lstm(x, (h0, c0))  \n",
    "        \n",
    "        # Decode hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :])  \n",
    "        return out\n",
    "\n",
    "rnn = RNN(input_size, hidden_size, num_layers, num_classes)\n",
    "\n",
    "\n",
    "# Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3\n",
      "\n",
      " 9\n",
      " 1\n",
      " 7\n",
      " 3\n",
      " 1\n",
      " 8\n",
      " 2\n",
      " 2\n",
      "[torch.LongTensor of size 8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        print(images.dim())\n",
    "        images = Variable(images.view(-1, sequence_length, input_size))\n",
    "        \n",
    "        print(images.dim())\n",
    "        print(labels)\n",
    "        break\n",
    "        \n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = rnn(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test the Model\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, sequence_length, input_size))\n",
    "    outputs = rnn(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "\n",
    "print('Test Accuracy of the model on the 10000 test images: %d %%' % (100 * correct / total)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
